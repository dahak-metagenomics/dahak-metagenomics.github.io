{
    "docs": [
        {
            "location": "/",
            "text": "Dahak Metagenomics\n\u00b6\n\n\nDahak Metagenomics\n is a project to build workflows for non-clinical metagenomic analyses.\n\n\nFind the dahak-metagenomics organization on Github at \n\nhttps://github.com-metagenomics\n.\n\n\nDahak\n\u00b6\n\n\nDahak is a software suite that integrates state-of-the-art open source tools\nfor metagenomic analyses. Tools in the dahak software suite will perform\nvarious steps in metagenomic analysis workflows including data pre-processing,\nmetagenome assembly, taxonomic and functional classification, genome binning,\nand gene assignment. We aim to deliver the analytical framework as a robust and\nreliable containerized workflow system, which will be free from dependency,\ninstallation, and execution problems typically associated with other\nopen-source bioinformatics solutions. This will maximize the transparency, data\nprovenance (i.e., the process of tracing the origins of data and its movement\nthrough the workflow), and reproducibility.\n\n\nFind the dahak repository on Github at \n\nhttps://github.com/dahak-metagenomics/dahak\n.\n\n\nGetting Started\n\u00b6\n\n\nAnalysis protocols can be found in the\n\nworkflows\n\ndirectory. It is assumed that analysis will begin with \nread\nfiltering\n\nand instructions for Docker installation are included there. \n\n\nYou can run these protocols interactively using Docker or automate them using\nSnakemake and Singularity. See the workflows\n\nREADME\n\nfor Docker, Snakemake and, Singularity install instructions. \n\n\nThe assembly, comparison, functional inference, and taxonomic classification\nworkflows are dependent upon the output of the read filtering workflow data.\nYou can download our data to use in the read filtering protocol from the \n\nOpen Science Framework (OSF)\n. See the section\nbelow titled Data and the read filtering protocol for more information. \n\n\nPrerequisites\n\u00b6\n\n\nCurrently, for the sake of simplicity, it is assumed that all workflow steps\nwill be run from Ubuntu 16.04 LTS.\n\n\ndahak is not a standalone program, but rather a collection of workflows\nthat are defined in snakemake files and that utilize bioconda and Docker\nto install and run software for different tasks.\n\n\nSee the \nworkflows/\n directory to get started.\n\n\nData\n\u00b6\n\n\nFor purposes of benchmarking this project will use the following datasets: \n\n\n\n\n\n\n\n\nDataset\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nShakya complete\n\n\nComplete metagenomic dataset from Shakya et al., 2013\n*\n containing bacterial and archaeal genomes\n\n\n\n\n\n\nShakya subset 50\n\n\n50 percent of the reads from Shakya complete\n\n\n\n\n\n\nShakya subset 25\n\n\n25 percent of the reads from Shakya complete\n\n\n\n\n\n\nShakya subset 10\n\n\n10 percent of the reads from Shakya complete\n\n\n\n\n\n\n\n\n*\nShakya, M., C. Quince, J. H. Campbell, Z. K. Yang, C. W. Schadt and M. Podar (2013). \"Comparative metagenomic and rRNA microbial diversity characterization using archaeal and bacterial synthetic communities.\" Environ Microbiol 15(6): 1882-1899.\n\n\nContributing\n\u00b6\n\n\nPlease read \nCONTRIBUTING.md\n for details on our code of conduct and the process for submitting pull requests to us.\n\n\nContributors\n\u00b6\n\n\nPhillip Brooks\n1\n, Charles Reid\n1\n, Bruce Budowle\n2\n, Chris Grahlmann\n3\n, Stephanie L. Guertin\n3\n, F. Curtis Hewitt\n3\n, Alexander F. Koeppel\n4\n, Oana I. Lungu\n3\n, Krista L. Ternus\n3\n, Stephen D. Turner\n4,\n5\n, C. Titus Brown\n1\n\n\n1\nSchool of Veterinary Medicine, University of California Davis, Davis, CA, United States of America \n\n\n2\nInstitute of Applied Genetics, Department of Molecular and Medical Genetics, University of North Texas Health Science Center, Fort Worth, Texas, United States of America\n\n\n3\nSignature Science, LLC, Austin, Texas, United States of America\n\n\n4\nDepartment of Public Health Sciences, University of Virginia, Charlottesville, VA, United States of America\n\n\n5\nBioinformatics Core, University of Virginia School of Medicine, Charlottesville, VA, United States of America\n\n\nSee also the list of \ncontributors\n who participated in this project.\n\n\nLicense\n\u00b6\n\n\nThis project is licensed under the BSD 3-Clause License - see the\n\nLICENSE\n file\nfor details.\n\n\nAcknowledgments\n\u00b6\n\n\n\n\nBioconda\n \n\n\nHat tip to anyone whose code was used\n\n\n\n\nLinks to Github Repositories\n\u00b6\n\n\n\n\ndahak\n\n\ndahak-taco\n\n\ndahak-yeti\n\n\ntaco-simple\n\n\ntaco-read-filtering\n\n\ntaco-taxonomic-classification",
            "title": "Index"
        },
        {
            "location": "/#dahak-metagenomics",
            "text": "Dahak Metagenomics  is a project to build workflows for non-clinical metagenomic analyses.  Find the dahak-metagenomics organization on Github at  https://github.com-metagenomics .",
            "title": "Dahak Metagenomics"
        },
        {
            "location": "/#dahak",
            "text": "Dahak is a software suite that integrates state-of-the-art open source tools\nfor metagenomic analyses. Tools in the dahak software suite will perform\nvarious steps in metagenomic analysis workflows including data pre-processing,\nmetagenome assembly, taxonomic and functional classification, genome binning,\nand gene assignment. We aim to deliver the analytical framework as a robust and\nreliable containerized workflow system, which will be free from dependency,\ninstallation, and execution problems typically associated with other\nopen-source bioinformatics solutions. This will maximize the transparency, data\nprovenance (i.e., the process of tracing the origins of data and its movement\nthrough the workflow), and reproducibility.  Find the dahak repository on Github at  https://github.com/dahak-metagenomics/dahak .",
            "title": "Dahak"
        },
        {
            "location": "/#getting-started",
            "text": "Analysis protocols can be found in the workflows \ndirectory. It is assumed that analysis will begin with  read\nfiltering \nand instructions for Docker installation are included there.   You can run these protocols interactively using Docker or automate them using\nSnakemake and Singularity. See the workflows README \nfor Docker, Snakemake and, Singularity install instructions.   The assembly, comparison, functional inference, and taxonomic classification\nworkflows are dependent upon the output of the read filtering workflow data.\nYou can download our data to use in the read filtering protocol from the  Open Science Framework (OSF) . See the section\nbelow titled Data and the read filtering protocol for more information.",
            "title": "Getting Started"
        },
        {
            "location": "/#prerequisites",
            "text": "Currently, for the sake of simplicity, it is assumed that all workflow steps\nwill be run from Ubuntu 16.04 LTS.  dahak is not a standalone program, but rather a collection of workflows\nthat are defined in snakemake files and that utilize bioconda and Docker\nto install and run software for different tasks.  See the  workflows/  directory to get started.",
            "title": "Prerequisites"
        },
        {
            "location": "/#data",
            "text": "For purposes of benchmarking this project will use the following datasets:      Dataset  Description      Shakya complete  Complete metagenomic dataset from Shakya et al., 2013 *  containing bacterial and archaeal genomes    Shakya subset 50  50 percent of the reads from Shakya complete    Shakya subset 25  25 percent of the reads from Shakya complete    Shakya subset 10  10 percent of the reads from Shakya complete     * Shakya, M., C. Quince, J. H. Campbell, Z. K. Yang, C. W. Schadt and M. Podar (2013). \"Comparative metagenomic and rRNA microbial diversity characterization using archaeal and bacterial synthetic communities.\" Environ Microbiol 15(6): 1882-1899.",
            "title": "Data"
        },
        {
            "location": "/#contributing",
            "text": "Please read  CONTRIBUTING.md  for details on our code of conduct and the process for submitting pull requests to us.",
            "title": "Contributing"
        },
        {
            "location": "/#contributors",
            "text": "Phillip Brooks 1 , Charles Reid 1 , Bruce Budowle 2 , Chris Grahlmann 3 , Stephanie L. Guertin 3 , F. Curtis Hewitt 3 , Alexander F. Koeppel 4 , Oana I. Lungu 3 , Krista L. Ternus 3 , Stephen D. Turner 4, 5 , C. Titus Brown 1  1 School of Veterinary Medicine, University of California Davis, Davis, CA, United States of America   2 Institute of Applied Genetics, Department of Molecular and Medical Genetics, University of North Texas Health Science Center, Fort Worth, Texas, United States of America  3 Signature Science, LLC, Austin, Texas, United States of America  4 Department of Public Health Sciences, University of Virginia, Charlottesville, VA, United States of America  5 Bioinformatics Core, University of Virginia School of Medicine, Charlottesville, VA, United States of America  See also the list of  contributors  who participated in this project.",
            "title": "Contributors"
        },
        {
            "location": "/#license",
            "text": "This project is licensed under the BSD 3-Clause License - see the LICENSE  file\nfor details.",
            "title": "License"
        },
        {
            "location": "/#acknowledgments",
            "text": "Bioconda    Hat tip to anyone whose code was used",
            "title": "Acknowledgments"
        },
        {
            "location": "/#links-to-github-repositories",
            "text": "dahak  dahak-taco  dahak-yeti  taco-simple  taco-read-filtering  taco-taxonomic-classification",
            "title": "Links to Github Repositories"
        }
    ]
}